---
title: "Style Transfer"
assignment: 4
author: "Miles Conn"
---
import { Image } from 'astro:assets';
import Experiments from "../../assets/assgn4/Experiments.astro";
import Experiment8 from "../../assets/assgn4/Experiment8.astro";
import Experiment2 from "../../assets/assgn4/Experiment2.astro";
import Experiment1Loss from "../../assets/assgn4/Experiment1Loss.astro";
import Experiment2Loss from "../../assets/assgn4/Experiment2Loss.astro";
import Experiment4 from "../../assets/assgn4/Experiment4.astro";
import Experiment4Loss from "../../assets/assgn4/Experiment4loss.astro";
import CaptionedImageGallery from "../../components/CaptionedImageGallery.astro";
import Latex from "../../components/Latex.astro";
import ILatex from "../../components/InlineLatex.astro";
import CaptionedImage from "../../components/CaptionedImage.astro";
import Mine from "../../assets/assgn4/Mine.astro";

import ExperimentAllRuns from "../../assets/assgn4/AllRunsExperiment.astro";
import Weird from "../../assets/assgn4/OptimizerWeird.astro";
import Adversarial from "../../assets/assgn4/adversarial.astro";
import StyleLossFinal from "../../assets/assgn4/experiment3/styleloss_1_3_4_300.jpeg";

# Experiments

## Finetuning Content Loss

The content loss at a layer is defined as the MSE Loss between the features of the current image being optimized and the content image. Intuitively then it makes sense that the content loss would be most effective at `conv_1` as this layer captures features that're less abstract than downstream layers, less transformed, and closer to 'true' L2 pixel loss. This was my suspicion and it was confirmed. `conv_1` loss converges much more quickly than loss at other layers. The following table shows the loss per layer per iteration.

<Experiment1Loss />

As you can see loss for `conv_1` converges within the first 100 iterations and results in a lower overall loss than all the other layers. The loss for deeper layers is higher as expected. Throughout the rest of the experiments we'll use `conv_1` for our content loss.

## Results of Finetuning Content Loss

<Experiment2 />

Here is a table of loss. 

<Experiment2Loss />

The difference between the inputs was `1253` which makes sense as it's just noise while their difference at the end was `3.41`. `Noise 1` had an L2 Loss of `2.5185` with ground truth while `Noise 2` had an L2 Loss of `2.3263`. Pretty good!

## Texture Synthesis 

Similar to `content_loss` we want to compute style loss as well. What is style loss? One idea is to use the Gram Matrix which is the correlation of two vectors in every dimension. This is just <ILatex formula="G = XX^T" />. We then want to minimize the loss between our computed gram matrix and the gram matrix encoding the style of our style target. Unlike content where as we get deeper the L2 loss becomes less meaningful with style it's certaintly possible for important style information to be encoded by deeper layers. 

To find the ideal style loss I just ran texture synthesis over all possible combinations of layers to calculate style loss at. The below table summarizes the results.

### Texture Synthesis Tuning

Note the leftmost column indicates which `conv` layers were being used ie `12 --> conv_1, conv_2`

<Experiments />

I ended up going with `1_3_4` just because I liked it. For reference, `1_3_4` had a style loss of `3.466813` after 300 iterations while `1_2_3_4_5` the initial default 
iteration had a loss of `14.167436` after 300 iterations. There were experiments with lower losses like `1_2_3_4` with `2.999`  or `1_2_4` with `1.36` but I didn't like the look 
as much.

I think that each layer captures more of the higher or lowever levels of style details which makes sense. As you go from top to bottom the details go from coarser to finer showing the effects of deeper layers.

<CaptionedImage src={StyleLossFinal} caption="Texture synthesis generated by calculating style loss at `conv_1`, `conv_3`, `conv_4`. After 300 iterations this resulted in a loss of `3.466813`"/>

### Texture Synthesis Results

Similar to the content loss experiments above here is texture synthesis run on two noise patterns.

<Experiment4/>

<Experiment4Loss/>

The L2 loss between the outputs was 307 which makes sense as there's no reason for them to have a low pixel loss. 

As you can see the texture differ in their layout but do indeed capture the starry night texture. Going forward I'll use `conv_1, conv_3, conv_4` to calculate style loss. 


# Hyperparameter Tuning

To figure out the hyper parameters for content and style weight I ran a
 search over params 
`[1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06, 1.e+07,
       1.e+08]`

for `style_weight` and `content_weight`. 

This generated a lot of images and a lot of optimizer instability at weird ratios. In retrospect it would've made more sense to have just do a search over the relative ratios of weight and style. That said, I would've never discovered the optimizer instability.

Below are some of the weird results.

<Weird/>
 
I settled on relative ratios of `content_weights = 1, style_weights = 1000000`

## Final Results

Below are the final results with all the previous experiments.

<ExperimentAllRuns />

Below are some of the weird results.

I found there was no difference in runtime which was bizarre. I also think that my noise strength was too strong for noise intilization. If I had run them longer than 300 iterations maybe the content loss would've gone down but I'm very happy with the content intilization ones.

Finally there are some of my own images. 

<Mine />

# Bells & Whistles

## Other Images

I also ran my style transfer on images from previous assignments. I did a poor job cropping the matplotlib edges and so we get to see stylized matplotlib templates. More papers should have stylized matplotlib templates. 

<Experiment8 />

## Adversarial Learning 

Recently I was listening to the [following podcast](https://oxide.computer/podcasts/oxide-and-friends/1814285) on the show Oxide & Friends about Adversarial Machine Learning. They talked about how they optimize their images for a dual loss of desired adversarial behaviour 
while also not getting stopped by safety filters. In a classic classification vision context this would mean optimizing for a model to say that an image is an apple when really it's a banana. 

Anyways, I had the idea from this that instead of treating loss as strictly positive I could optimize for two different things. In general I ran experiments where I subtracted content loss from later layers from my base layer with the effect that hopefully the optimizer would 
lead to images that have high loss for deeper features. My initial experiments I thought were a failure until after playing around with the parameters I began to see Falling Water emerge. Below are my results as well as their parameters. 

<Adversarial />

All results were initially using `conv3` as our negative content layer. The nubmer then indicates the following experiments: 
```
1 --> 0.00001 content_weight=100 style_weight =1000000 
2 --> 0.0001 content_weight=100 style_weight =1000000 
3 --> 0.0001 content_weight=100 style_weight =1000000  now using conv_2 as our base layer
4 --> conv1 as base layer and conv5 as negative layer
5 --> conv1 as base layer and conv4, conv5 as negative layer
```

While not perfect the results indicate that you can do interesting things like penalizing certain details while emphasizing others. For instance, there seems to be more style transfer on the borders letting the house remain. 


### Results

# Appendix 

All tests were run with the following fixed rand seed

```python
RAND_SEED = 152
torch.manual_seed(RAND_SEED)
random.seed(RAND_SEED
```