---
title: "Poisson Blending"
assignment: 2
author: "Miles Conn"
---
import { Image } from 'astro:assets';
import CaptionedImageGallery from "../../components/CaptionedImageGallery.astro";
import Latex from "../../components/Latex.astro";
import ILatex from "../../components/InlineLatex.astro";
import ToyProblem from "../../assets/assgn2/toy_problem.png";
import Plane from "../../assets/assgn2/fig12904812904812.png";
import Tile from "../../assets/assgn2/fig12908412908412.png";
import Penguin from "../../assets/assgn2/fig0129481290841209.png";
import Penguin2 from "../../assets/assgn2/Figure_902385.png";
import Penguin3 from "../../assets/assgn2/Figure_1237890.png";
import Bear from "../../assets/assgn2/bear.png";

import ChildTarget from "../../assets/assgn2/target_01.jpg";
import BearSource from "../../assets/assgn2/source_01.jpg";
import Penguin2Source from "../../assets/assgn2/penguin2.jpg";
import Pengiun1Source from "../../assets/assgn2/penguin1.jpg";
import SkyTarget from "../../assets/assgn2/demo5_target_resized.jpg";
import Skiiers from "../../assets/assgn2/demo3_target.png";
import PlaneSource from "../../assets/assgn2/demo5_resized.jpg";
import HandWriting from "../../assets/assgn2/demo2_source_resized.jpg";
import TileTarget from "../../assets/assgn2/demo4_target_resized.jpg";
import Poland from "../../assets/assgn2/2015_Kościół_Zmartwychwstania_Pańskiego_w_Stroniu_Śląskim_01_resized.JPG";

import Ishihara74 from "../../assets/assgn2/Ishihara74_500x500.png";
import Ishihara74S from "../../assets/assgn2/Ishihara74_500x500 (1).png";
import Ishihara42 from "../../assets/assgn2/Ishihara42_500x500.PNG";
import Ishihara42S from "../../assets/assgn2/Ishihara42_500x500 (1).PNG";
import Ishihara6 from "../../assets/assgn2/Ishihara6_500x500.PNG";
import Ishihara6S from "../../assets/assgn2/Ishihara6_500x500 (1).PNG";
import Ishihara5 from "../../assets/assgn2/Ishihara5_500x500.jpg";
import Ishihara5S from "../../assets/assgn2/Ishihara5_500x500 (1).jpg";
import Ishihara2 from "../../assets/assgn2/Ishihara2_500x500.png";
import Ishihara2S from "../../assets/assgn2/Ishihara2_500x500 (1).png";
import Ishihara12 from "../../assets/assgn2/c2gray_2.png";
import Ishihara12S from "../../assets/assgn2/Ishihara12_500x500.png";

# Explanation 

This project explores gradient-domain processing a technique that uses
gradients to better blend images together. We start off with a toy problem recovering 
an image from x,y gradients and then move on to poisson blending. 

Our main goal throughout this assignment is to solve for 

<Latex formula="v = \argmin_{v} \sum_{i \in S, j \in N_i \cap S} ((v_i - v_j) - (s_i - s_j))^2 + \sum_{i\in S, j \in N_i \cap \neg S}((v_i - t_j) - (s_i - s_j))^2 "/>

where <ILatex formula="s_x"/> represents pixels in our source image, <ILatex formula="t_x" /> represents
pixels in our target image, and <ILatex formula ="N_i"/> represents our mask (this is an oversimplification we'll correct later).

In essence we want to find <ILatex formula='v_i - v_j'/>, a new gradient, such that it's L2 loss compared to the gradient
of our source image is minimized. We do this by constructing the matrices 
<ILatex formula='A,b'/> and using a least squares solver to find <ILatex formula='v'/> such that
<ILatex formula='Av=b'/>. 

Note our matrices were fairly sparse so throughout we use sparses matrices to speed up computation.

I found this assignment somewhat frustrating because the results could either be really good or really bad. When they were really bad I went through all my code looking for errors 
only to realize this method, as implemented, can be incredibly brittle. 

## Toy Problem

Our toy problem introduces us to gradient processing and asks us to reconstruct an image from its gradients.

Using `s(x,y)` to denote intensities at `(x,y)` and `v(x,y)` to denote the pixels we want to solve for
we come up with the following three equations.

1. Minimize <ILatex formula='((v(x+1,y) - v(x,y)) - (s(x+1,y) - s(x,y)))^2'/> ie the x-gradients should match
2. Minimize <ILatex formula='((v(x,y+1) - v(x,y)) - (s(x,y+1) - s(x,y)))^2'/> ie the y-gradients should match
3. Minimize <ILatex formula='(v(1,1), - s(1,1))^2'/> the top left corner should match exactly (this is essentially assignment). 

In code this looks like the following for the `x-gradient`:
```python
A[..., im2var[y, x + 1]] = 1 
A[..., im2var[y, x]] = -1
b[...] = s[y, x + 1] - s[y, x] # x-gradient at y,x
```

We are solving for the corresponding `v_i, v_j` such that 
`(v_i - v_j) - (s[y,x+1] - s[y,x])` is minimized. `im2var` can be thought of as mapping coordinates to variables. 

Our results are below: 
<>
<Image src={ToyProblem}  alt=""/>
<figcaption class="text-center mb-10">
ToyProblem. With L2 difference of `.348` we've almost perfectly reconstructed the input.
</figcaption>
</>

## Poisson Blending

For the main part of the assignment we want to solve a similar equation as above but with some more steps. We'll use the terminology `source` to refer to the image that's getting blended in, `target` to be the background that's getting blended onto, and then `mask` to refer to a mask over our source. 

<Latex formula="v = \argmin_{v} \sum_{i \in S, j \in N_i \cap S} ((v_i - v_j) - (s_i - s_j))^2 + \sum_{i\in S, j \in N_i \cap \neg S}((v_i - t_j) - (s_i - s_j))^2 "/>

While this equation can seem intimidating we'll break it down.

- <ILatex formula='i\in S, s_i, s_j'/> covers pixels in our 'source' image and within our mask. Here we want the new solved pixels to have a small gradient. `j` is the 4 pixels above, below, to the left, and to the right of our target pixel `v_i`.  
- If we are outside our mask ie <ILatex formula='i \in N_i \cap \neg S_i'/> then we are dealing with pixels on the border of our mask. In this case we want to minimize `(v_i - t_j) - (s_i - s_j)` where `t_j` is not from our source but our target image. The idea being we want a smooth transition to the background image and thus want to minimize our edge gradient.

As in the toy example we build sparse matrices and then use `scipy.lsqr` to solve them. 

### Results

First we present some our source materials. The first column is the target and the other columns are various sources. 
<CaptionedImageGallery layout="3x3" captions="">
<Image src={ChildTarget}  alt="" slot="images"/>
<Image src={BearSource}  alt="" slot="images" />
<div slot="images"></div>

<Image src={Poland}  alt="" slot="images"/>
<Image src={Penguin2Source}  alt="" slot="images" />
<Image src={Pengiun1Source}  alt="" slot="images" />
<Image src={Skiiers}  alt="" slot="images"/>
<div slot="images"></div>
<div slot="images"></div>


<Image src={SkyTarget}  alt="" slot="images"/>
<Image src={PlaneSource}  alt="" slot="images" />
<div slot="images"/>

<Image src={TileTarget}  alt="" slot="images" />
<Image src={HandWriting}  alt="" slot="images" />
</CaptionedImageGallery>

Now we show our results. 

<>
<Image src={Plane}  alt=""/>
<figcaption class="text-center mb-10">
Plane with a nice sunset
</figcaption>
</>

<>
<Image src={Tile}  alt=""/>
<figcaption class="text-center mb-10">
Writing on tile. Notice how with mixed blending the underlying grout shows through. Exactly what we want.
</figcaption>
</>

<>
<Image src={Penguin}  alt=""/>
<figcaption class="text-center mb-10">
A penguin with skiers. Note how with the bad mask we get lots of blurring with poisson blending and with mixed blending the background bleeds through the penguin. 
</figcaption>
</>

<>
<Image src={Penguin2}  alt=""/>
<figcaption class="text-center mb-10">
More penguins on a field. Once again these results aren't great. The dark grass makes the penguin much darker than it needs to be and with mixed blending we've lost the body of the penguin! This makes sense as the gradient across a solid white surface is going to be zero compared to the texture grass below.
</figcaption>
</>

<>
<Image src={Penguin3}  alt=""/>
<figcaption class="text-center mb-10">
Even more bad penguins! Here the background of the penguin that got included in the mask was very complicated leading to bad results. The penguin also developed an undesirable green cast because it's overlayed over grass. Generally this technique comes out better when you have solid monotone backgrounds as they blend more easily.
</figcaption>
</>

<>
<Image src={Bear}  alt=""/>
<figcaption class="text-center mb-10">
Swimmer with bear. Look out!
</figcaption>
</>

# Bells & Whistles

## Mixed Gradients

We now want to minimize the following 

<Latex formula="v = \argmin_{v} \sum_{i \in S, j \in N_i \cap S} ((v_i - v_j) - d_ij)^2 + \sum_{i\in S, j \in N_i \cap \neg S}((v_i - t_j) - d_ij)^2 "/>
where <ILatex formula="d_{ij}"/> is defined as 

```python
if abs(s_i - s_j) >= abs (t_i - t_j):
    d_ij = s_i - s_j
else:
    d_ij = t_i - t_j
```

The results for mixed gradients are displayed above. Because the strongest gradient is allowed through there were weird results where the background would bleed through the target. This was desired when
the target was handwriting and we wanted to preserve the tile underneath but was less desired with the penguin on the grass. One interesting result I found is that with a bad mask this strategy led to much better results. With poisson blending a bad mask could leading
to weird blur which this method avoided. This is probably because a bad mask let in more background than it needed and the backgrounds had smaller derivatives that got ignored leading to better blending even with a bad mask. You can see this with the various penguins, even though the background bled through the chest of the penguin the edge's, where the bad masking is, look really good. Perhaps a dual strategy could be employed to get the best of both worlds.

## color2Gray

This was a disappointing experiment as, it should've worked but failed miserably. The main idea is we convert the image
to gray `naively` and then we find the number and find the layer with the greatest contrast in the `HSV` color space and then use the number as a mask to pertube the values
in the `naive` conversion. This way we can make the resulting image contrastier without deviating too much from a grayscale image and still maintaining the key contrast of the colored image. `V` was used as it often maintained the contrast of the original image.

I spent way too much time on my automasking code only to realize my results weren't as strong as I would've liked them.
My automasking strategy was in the `H` layer I created 3 bins with <ILatex formula='\mu \pm \{\sigma, 0\}'/>
and then autobinned pixels and took the upper most bin or lowest bin indices to form my mask. This strategy was developed as I noticed in `H` there would be a strong positive or  negative (ie lack of) activation where the numbers were. This strategy worked great for samples like 74, or 6, but failed other times. 


### Results

As mentioned my results leave a lot to be desired, either the mask failed or the resulting image wasn't pertrubed as much as I would've liked.

<>
<Image src={Ishihara74}  alt=""/>
<figcaption class="text-center mb-10">
Ishihara 74, V isn't that contrasty so the results don't get pertrubed in a noticeable way
</figcaption>
</>

<>
<Image src={Ishihara42}  alt=""/>
<figcaption class="text-center mb-10">
Ishihara 42, the auto mask failed, we can see H doesn't have an obvious way to partition it.
</figcaption>
</>

<>
<Image src={Ishihara6}  alt=""/>
<figcaption class="text-center mb-10">
Ishihara 6 - this worked!
</figcaption>
</>

<>
<Image src={Ishihara5}  alt=""/>
<figcaption class="text-center mb-10">
Ishihara 5 - we chose the wrong bins and hence our mask is really bad.
</figcaption>
</>

<>
<Image src={Ishihara2}  alt=""/>
<figcaption class="text-center mb-10">
Ishihara 2
</figcaption>
</>

<>
<Image src={Ishihara12}  alt=""/>
<figcaption class="text-center mb-10">
Ishihara 12. This one actually worked but Matplotlib's `c2gray` is doing some weird tone mapping making it not seem apparent.
</figcaption>
</>

Original Ishihara colorblind tests 
<CaptionedImageGallery layout="3x3" captions="">
<Image src={Ishihara12S}  alt="" slot="images"/>
<Image src={Ishihara74S}  alt="" slot="images"/>
<Image src={Ishihara42S}  alt="" slot="images"/>
<Image src={Ishihara6S}  alt="" slot="images"/>
<Image src={Ishihara5S}  alt="" slot="images"/>
<Image src={Ishihara2S}  alt="" slot="images"/>
<Image src={Ishihara12S}  alt="" slot="images"/>
</CaptionedImageGallery>

# Conclusion

As I said I struggled more than I should have with this assignment as I often thought my code wasn't working when really it was just brittle. The concept of gradient domain processing is very powerful but to get it to work across a variety of workloads would require a lot more finetuning and analysis.